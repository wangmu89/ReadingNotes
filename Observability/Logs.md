优缺点

- 优点
  - 容易生成的，日志的格式是一个字符串、JSON格式的Blob（BinaryLargeOBjects）、k-v键值对格式这一事实，使得以日志行的形式表示任何数据变得很容易。
  - 大多数语言、应用程序框架和库都支持日志记录。
  - 日志也很容易检测，添加一个日支行就像添加一条打印语句一样简单。
  - 只要将搜索空间，定位于单个服务中发生的事件，日志就可以很好地呈现包含丰富本地上下文的高粒度信息。
  
- 缺点

  - 日志库性能可能存在不足，日志记录的开销，可能导致应用程序很容易收到次优性能的影响。

  - 日志消息可能丢失（除非通过使用RELP之类的协议保证消息的可靠传递），当日志用于计费或者支付目的时，更需要保证不能出现丢失。

    ```markdown
    RELP不是银弹
    RELP是一种使用命令-响应模型的协议（TODO 需要详细了解下RELP，命令和响应称为 RELP 事务）。
    RELP客户端发出命令 -> RELP服务器端响应这些命令。
    RELP回严格要求可能适用于每个日志行都至关重要或法律要求用于审计目的的场景，但监控和调试很少（如果有的话）需要如此严格的保证和随之而来的复杂性。
    ```

  - 日志过多可能会对应用程序性能产生不利影响，日志库需要动态采样（dynamically sample）处理。特别当日志不是异步的，并且将日支行写入磁盘或标注输出时会阻塞请求处理，这种情况（指的是对应用程序性能产生不利影响）会更严重。

    ```markdown
    采样还是不采样？
    智能采样（sample intelligently）是应对日志记录开销的一种常用解决方法。采样：从生成的事件日志总数中挑选一小部分进行处理和存储的技术，系统中生成的事件语料库的缩影。
    	- 公平问题，采样数据集的有效性取决于数据集的所选键或特征，根据这些键或特征做出采样决策。
    	- 其次有必要确定如何动态采样，以便采样率根据传入流量的形状进行自我调整。
    ```

在处理方面，原始日志几乎总是由 Logstash、fluentd、Scribe 或 Heka 等工具进行规范化、过滤和处理，然后再保存在 Elasticsearch 或 BigQuery 等数据存储中。 如果应用程序生成大量日志，则日志可能需要在 Kafka 等代理中进一步缓冲，然后才能由 Logstash 处理。 像 BigQuery 这样的托管解决方案有一个不能超过的配额。

在存储方面，ES作为一个出色的搜索引擎，但是运营它的成本并不低，即使有专门的运营ES的专家团队，也可能存在一些缺陷。一个恰当的示例：在 Kibana 的图表中看到急剧下降的情况并不少见，这不是因为服务的流量正在下降，而是因为 Elasticsearch 无法跟上被抛出的海量数据的索引。 即使日志摄取处理在 Elasticsearch 中不是问题，我认识的人似乎也没有完全弄清楚如何使用 Kibana 的 UI，更不用说享受使用它了。

